---
title: "9.7.14.4. Matrix multiply-accumulate operation usingwmmainstructions"
section: 9.7.14.4
url: https://docs.nvidia.com/cuda/parallel-thread-execution/
---

#### 9.7.14.4. Matrix multiply-accumulate operation usingwmmainstructions


This section describes warp level `wmma.load, wmma.mma` and `wmma.store` instructions and the organization of various matrices invovled in these instruction.

#####  9.7.14.4.1. [Matrix Fragments for WMMA](<#warp-level-matrix-fragment>)  
  
Each thread in the warp holds a fragment of the matrix. The distribution of fragments loaded by the threads in a warp is unspecified and is target architecture dependent, and hence the identity of the fragment within the matrix is also unspecified and is target architecture dependent. The fragment returned by a `wmma` operation can be used as an operand for another `wmma` operation if the shape, layout and element type of the underlying matrix matches. Since fragment layout is architecture dependent, using the fragment returned by a `wmma` operation in one function as an operand for a `wmma` operation in a different function may not work as expected if the two functions are linked together but were compiled for different link-compatible SM architectures. Note passing `wmma` fragment to a function having `.weak` linkage is unsafe since at link time references to such function may get resolved to a function in different compilation module.

Each fragment is a vector expression whose contents are determined as follows. The identity of individual matrix elements in the fragment is unspecified.

Integer fragments

Multiplicands (A or B):

Data-type | Shape | Matrix | Fragment  
---|---|---|---  
`.u8` or `.s8` | `.m16n16k16` | A | A vector expression of two `.b32` registers, with each register containing four elements from the matrix.  
B | A vector expression of two `.b32` registers, with each register containing four elements from the matrix.  
| `.m8n32k16` | A | A vector expression containing a single `.b32` register containing four elements from the matrix.  
B | A vector expression of four `.b32` registers, with each register containing four elements from the matrix.  
| `.m32n8k16` | A | A vector expression of four `.b32` registers, with each register containing four elements from the matrix.  
B | A vector expression containing single `.b32` register, with each containing four elements from the matrix.  
  
Accumulators (C or D):

Data-type | Shape | Fragment  
---|---|---  
`.s32` | `.m16n16k16` | A vector expression of eight `.s32` registers.  
`.m8n32k16`  
`.m32n8k16`  
  
Floating point fragments

Data-type | Matrix | Fragment  
---|---|---  
`.f16` | A or B | A vector expression of eight `.f16x2` registers.  
`.f16` | C or D | A vector expression of four `.f16x2` registers.  
`.f32` | A vector expression of eight `.f32` registers.  
  
Floating point fragments for `.bf16` data format

Multiplicands (A or B):

Data-type | Shape | Matrix | Fragment  
---|---|---|---  
`.bf16` | `.m16n16k16` | A | A vector expression of four `.b32` registers, with each register containing two elements from the matrix.  
B  
`.m8n32k16` | A | A vector expression containing a two `.b32` registers, with containing two elements from the matrix.  
B | A vector expression of eight `.b32` registers, with each register containing two elements from the matrix.  
`.m32n8k16` | A | A vector expression of eight `.b32` registers, with each register containing two elements from the matrix.  
B | A vector expression containing two `.b32` registers, with each containing two elements from the matrix.  
  
Accumulators (C or D):

Data-type | Matrix | Fragment  
---|---|---  
`.f32` | C or D | A vector expression containing eight `.f32` registers.  
  
Floating point fragments for `.tf32` data format

Multiplicands (A or B):

Data-type | Shape | Matrix | Fragment  
---|---|---|---  
`.tf32` | `.m16n16k8` | A | A vector expression of four `.b32` registers.  
B | A vector expression of four `.b32` registers.  
  
Accumulators (C or D):

Data-type | Shape | Matrix | Fragment  
---|---|---|---  
`.f32` | `.m16n16k8` | C or D | A vector expression containing eight `.f32` registers.  
  
Double precision floating point fragments

Multiplicands (A or B):

Data-type | Shape | Matrix | Fragment  
---|---|---|---  
`.f64` | `.m8n8k4` | A or B | A vector expression of single `.f64` register.  
  
Accumulators (C or D):

Data-type | Shape | Matrix | Fragment  
---|---|---|---  
`.f64` | `.m8n8k4` | C or D | A vector expression containing single `.f64` register.  
  
Sub-byte integer and single-bit fragments

Multiplicands (A or B):

Data-type | Shape | Fragment  
---|---|---  
`.u4` or `.s4` | `.m8n8k32` | A vector expression containing a single `.b32` register, containing eight elements from the matrix.  
`.b1` | `.m8n8k128` | A vector expression containing a single `.b32` register, containing 32 elements from the matrix.  
  
Accumulators (C or D):

Data-type | Shape | Fragment  
---|---|---  
`.s32` | `.m8n8k32` | A vector expression of two `.s32` registers.  
`.m8n8k128` | A vector expression of two `.s32` registers.  
  
Manipulating fragment contents

The contents of a matrix fragment can be manipulated by reading and writing to individual registers in the fragment, provided the following conditions are satisfied:

  * All matrix element in the fragment are operated on uniformly across threads, using the same parameters.

  * The order of the matrix elements is not changed.


For example, if each register corresponding to a given matrix is multiplied by a uniform constant value, then the resulting matrix is simply the scaled version of the original matrix.

Note that type conversion between `.f16` and `.f32` accumulator fragments is not supported in either direction. The result is undefined even if the order of elements in the fragment remains unchanged.

#####  9.7.14.4.2. [Matrix Storage for WMMA](<#warp-level-matrix-storage>)

Each matrix can be stored in memory with a _row-major_ or _column-major_ layout. In a _row-major_ format, consecutive elements of each row are stored in contiguous memory locations, and the row is called the _leading dimension_ of the matrix. In a _column-major_ format, consecutive elements of each column are stored in contiguous memory locations and the column is called the _leading dimension_ of the matrix.

Consecutive instances of the _leading dimension_ (rows or columns) need not be stored contiguously in memory. The `wmma.load` and `wmma.store` operations accept an optional argument `stride` that specifies the offset from the beginning of each row (or column) to the next, in terms of matrix elements (and not bytes). For example, the matrix being accessed by a `wmma` operation may be a submatrix from a larger matrix stored in memory. This allows the programmer to compose a multiply-and-accumulate operation on matrices that are larger than the shapes supported by the `wmma` operation.

Address Alignment

The starting address of each instance of the leading dimension (row or column) must be aligned with the size of the corresponding fragment in bytes. Note that the starting address is determined by the base pointer and the optional `stride`.

Consider the following instruction as an example:
    
    
    wmma.load.a.sync.aligned.row.m16n16k16.f16 {x0,...,x7}, [p], s;
    

  * Fragment size in bytes = 32 (eight elements of type `.f16x2`)

  * Actual `stride` in bytes = 2 * `s` (since `stride` is specified in terms of `.f16` elements, not bytes)

  * For each row of this matrix to be aligned at fragment size the following must be true:

    1. `p` is a multiple of 32.

    2. `2*s` is a multiple of 32.


Default value for stride

The default value of the `stride` is the size of the _leading dimension_ of the matrix. For example, for an `MxK` matrix, the `stride` is `K` for a _row-major_ layout and `M` for a _column-major_ layout. In particular, the default strides for the supported matrix shapes are as follows:

Shape | A (row) | A (column) | B (row) | B (column) | Accumulator (row) | Accumulator (column)  
---|---|---|---|---|---|---  
16x16x16 | 16 | 16 | 16 | 16 | 16 | 16  
8x32x16 | 16 | 8 | 32 | 16 | 32 | 8  
32x8x16 | 16 | 32 | 8 | 16 | 8 | 32  
8x8x32 | 32 | 8 | 8 | 32 | 8 | 8  
8x8x128 | 128 | 8 | 8 | 128 | 8 | 8  
16x16x8 | 8 | 16 | 16 | 8 | 16 | 16  
8x8x4 | 4 | 8 | 8 | 4 | 8 | 8

#####  9.7.14.4.3. [Warp-level Matrix Load Instruction: `wmma.load`](<#warp-level-matrix-instructions-wmma-ld>)  
  
`wmma.load`

Collectively load a matrix from memory for WMMA

Syntax

Floating point format `.f16` loads:
    
    
    wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride};
    wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride};
    wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride};
    
    .layout = {.row, .col};
    .shape  = {.m16n16k16, .m8n32k16, .m32n8k16};
    .ss     = {.global, .shared{::cta}};
    .atype  = {.f16, .s8, .u8};
    .btype  = {.f16, .s8, .u8};
    .ctype  = {.f16, .f32, .s32};
    

Alternate floating point format `.bf16` loads:
    
    
    wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}
    wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}
    wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
    .layout = {.row, .col};
    .shape  = {.m16n16k16, .m8n32k16, .m32n8k16};
    .ss     = {.global, .shared{::cta}};
    .atype  = {.bf16 };
    .btype  = {.bf16 };
    .ctype  = {.f32 };
    

Alternate floating point format `.tf32` loads:
    
    
    wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}
    wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}
    wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
    .layout = {.row, .col};
    .shape  = {.m16n16k8 };
    .ss     = {.global, .shared{::cta}};
    .atype  = {.tf32 };
    .btype  = {.tf32 };
    .ctype  = {.f32 };
    

Double precision Floating point `.f64` loads:
    
    
    wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}
    wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}
    wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
    .layout = {.row, .col};
    .shape  = {.m8n8k4 };
    .ss     = {.global, .shared{::cta}};
    .atype  = {.f64 };
    .btype  = {.f64 };
    .ctype  = {.f64 };
    

Sub-byte loads:
    
    
    wmma.load.a.sync.aligned.row.shape{.ss}.atype r, [p] {, stride}
    wmma.load.b.sync.aligned.col.shape{.ss}.btype r, [p] {, stride}
    wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
    .layout = {.row, .col};
    .shape  = {.m8n8k32};
    .ss     = {.global, .shared{::cta}};
    .atype  = {.s4, .u4};
    .btype  = {.s4, .u4};
    .ctype  = {.s32};
    

Single-bit loads:
    
    
    wmma.load.a.sync.aligned.row.shape{.ss}.atype r, [p] {, stride}
    wmma.load.b.sync.aligned.col.shape{.ss}.btype r, [p] {, stride}
    wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
    .layout = {.row, .col};
    .shape  = {.m8n8k128};
    .ss     = {.global, .shared{::cta}};
    .atype  = {.b1};
    .btype  = {.b1};
    .ctype  = {.s32};
    

Description

Collectively load a matrix across all threads in a warp from the location indicated by address operand `p` in the specified state space into destination register `r`.

If no state space is given, perform the memory accesses using [Generic Addressing](<#generic-addressing>). `wmma.load` operation may be used only with `.global` and `.shared` spaces and with generic addressing, where the address points to `.global` or `.shared` space.

The mutually exclusive qualifiers `.a`, `.b` and `.c` indicate whether matrix A, B or C is being loaded respectively for the `wmma` computation.

The destination operand `r` is a brace-enclosed vector expression that can hold the fragment returned by the load operation, as described in [Matrix Fragments for WMMA](<#warp-level-matrix-fragment>).

The `.shape` qualifier indicates the dimensions of all the matrix arguments involved in the intended `wmma` computation.

The `.layout` qualifier indicates whether the matrix to be loaded is stored in _row-major_ or _column-major_ format.

`stride` is an optional 32-bit integer operand that provides an offset in terms of matrix elements between the start of consecutive instances of the _leading dimension_ (rows or columns). The default value of `stride` is described in [Matrix Storage for WMMA](<#warp-level-matrix-storage>) and must be specified if the actual value is larger than the default. For example, if the matrix is a sub-matrix of a larger matrix, then the value of stride is the leading dimension of the larger matrix. Specifying a value lower than the default value results in undefined behavior.

The required alignment for address `p` and `stride` is described in the [Matrix Storage for WMMA](<#warp-level-matrix-storage>).

The mandatory `.sync` qualifier indicates that `wmma.load` causes the executing thread to wait until all threads in the warp execute the same `wmma.load` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same `wmma.load` instruction. In conditionally executed code, a `wmma.load` instruction should only be used if it is known that all threads in the warp evaluate the condition identically, otherwise behavior is undefined.

The behavior of `wmma.load` is undefined if all threads do not use the same qualifiers and the same values of `p` and `stride`, or if any thread in the warp has exited.

`wmma.load` is treated as a _weak_ memory operation in the [Memory Consistency Model](<#memory-consistency-model>).

PTX ISA Notes

Introduced in PTX ISA version 6.0.

`.m8n32k16` and `.m32n8k16` introduced in PTX ISA version 6.1.

Integer, sub-byte integer and single-bit `wmma` introduced in PTX ISA version 6.3.

`.m8n8k4` and `.m16n16k8` on `wmma` introduced in PTX ISA version 7.0.

Double precision and alternate floating point precision `wmma` introduced in PTX ISA version 7.0.

Modifier `.aligned` is required from PTX ISA version 6.3 onwards, and considered implicit in PTX ISA versions less than 6.3.

Support for `::cta` sub-qualifier introduced in PTX ISA version 7.8.

Target ISA Notes

Floating point `wmma` requires `sm_70` or higher.

Integer `wmma` requires `sm_72` or higher.

Sub-byte and single-bit `wmma` requires `sm_75` or higher.

Double precision and alternate floating point precision `wmma` requires `sm_80` or higher.

Examples
    
    
    // Load elements from f16 row-major matrix B
    .reg .b32 x<8>;
    
    wmma.load.b.sync.aligned.m16n16k16.row.f16 {x0,x1,x2,x3,x4,x5,x,x7}, [ptr];
    // Now use {x0, ..., x7} for the actual wmma.mma
    
    // Load elements from f32 column-major matrix C and scale the values:
    .reg .b32 x<8>;
    
    wmma.load.c.sync.aligned.m16n16k16.col.f32
                     {x0,x1,x2,x3,x4,x5,x6,x7}, [ptr];
    
    mul.f32 x0, x0, 0.1;
    // repeat for all registers x<8>;
    ...
    mul.f32 x7, x7, 0.1;
    // Now use {x0, ..., x7} for the actual wmma.mma
    
    // Load elements from integer matrix A:
    .reg .b32 x<4>
    // destination registers x<4> contain four packed .u8 values each
    wmma.load.a.sync.aligned.m32n8k16.row.u8 {x0,x1,x2,x3}, [ptr];
    
    // Load elements from sub-byte integer matrix A:
    .reg .b32 x0;
    // destination register x0 contains eight packed .s4 values
    wmma.load.a.sync.aligned.m8n8k32.row.s4 {x0}, [ptr];
    
    // Load elements from .bf16 matrix A:
    .reg .b32 x<4>;
    wmma.load.a.sync.aligned.m16n16k16.row.bf16
                    {x0,x1,x2,x3}, [ptr];
    
    // Load elements from .tf32 matrix A:
    .reg .b32 x<4>;
    wmma.load.a.sync.aligned.m16n16k8.row.tf32
                    {x0,x1,x2,x3}, [ptr];
    
    // Load elements from .f64 matrix A:
    .reg .b32 x<4>;
    wmma.load.a.sync.aligned.m8n8k4.row.f64
                    {x0}, [ptr];

#####  9.7.14.4.4. [Warp-level Matrix Store Instruction: `wmma.store`](<#warp-level-matrix-instructions-wmma-st>)

`wmma.store`

Collectively store a matrix into memory for WMMA

Syntax
    
    
    wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride};
    
    .layout = {.row, .col};
    .shape  = {.m16n16k16, .m8n32k16, .m32n8k16};
    .ss     = {.global, .shared{::cta}};
    .type   = {.f16, .f32, .s32};
    
    wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}
    .layout = {.row, .col};
    .shape  = {.m8n8k32, .m8n8k128};
    .ss     = {.global, .shared{::cta}};
    .type   = {.s32};
    
    wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}
    .layout = {.row, .col};
    .shape  = {.m16n16k8};
    .ss     = {.global, .shared{::cta}};
    .type   = {.f32};
    
    wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}
    .layout = {.row, .col};
    .shape  = {.m8n8k4 };
    .ss     = {.global, .shared{::cta}};
    .type   = {.f64};
    

Description

Collectively store a matrix across all threads in a warp at the location indicated by address operand `p` in the specified state space from source register `r`.

If no state space is given, perform the memory accesses using [Generic Addressing](<#generic-addressing>). `wmma.load` operation may be used only with `.global` and `.shared` spaces and with generic addressing, where the address points to `.global` or `.shared` space.

The source operand `r` is a brace-enclosed vector expression that matches the shape of the fragment expected by the store operation, as described in [Matrix Fragments for WMMA](<#warp-level-matrix-fragment>).

The `.shape` qualifier indicates the dimensions of all the matrix arguments involved in the intended `wmma` computation. It must match the `.shape` qualifier specified on the `wmma.mma` instruction that produced the D matrix being stored.

The `.layout` qualifier indicates whether the matrix to be loaded is stored in _row-major_ or _column-major_ format.

`stride` is an optional 32-bit integer operand that provides an offset in terms of matrix elements between the start of consecutive instances of the _leading dimension_ (rows or columns). The default value of `stride` is described in [Matrix Storage for WMMA](<#warp-level-matrix-storage>) and must be specified if the actual value is larger than the default. For example, if the matrix is a sub-matrix of a larger matrix, then the value of stride is the leading dimension of the larger matrix. Specifying a value lower than the default value results in undefined behavior.

The required alignment for address `p` and `stride` is described in the [Matrix Storage for WMMA](<#warp-level-matrix-storage>).

The mandatory `.sync` qualifier indicates that `wmma.store` causes the executing thread to wait until all threads in the warp execute the same `wmma.store` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same `wmma.store` instruction. In conditionally executed code, a `wmma.store` instruction should only be used if it is known that all threads in the warp evaluate the condition identically, otherwise behavior is undefined.

The behavior of `wmma.store` is undefined if all threads do not use the same qualifiers and the same values of `p` and `stride`, or if any thread in the warp has exited.

`wmma.store` is treated as a _weak_ memory operation in the [Memory Consistency Model](<#memory-consistency-model>).

PTX ISA Notes

Introduced in PTX ISA version 6.0.

`.m8n32k16` and `.m32n8k16` introduced in PTX ISA version 6.1.

Integer, sub-byte integer and single-bit `wmma` introduced in PTX ISA version 6.3.

`.m16n16k8` introduced in PTX ISA version 7.0.

Double precision `wmma` introduced in PTX ISA version 7.0.

Modifier `.aligned` is required from PTX ISA version 6.3 onwards, and considered implicit in PTX ISA versions less than 6.3.

Support for `::cta` sub-qualifier introduced in PTX ISA version 7.8.

Target ISA Notes

Floating point `wmma` requires `sm_70` or higher.

Integer `wmma` requires `sm_72` or higher.

Sub-byte and single-bit `wmma` requires `sm_75` or higher.

Double precision `wmma` and shape `.m16n16k8` requires `sm_80` or higher.

Examples
    
    
    // Storing f32 elements computed by a wmma.mma
    .reg .b32 x<8>;
    
    wmma.mma.sync.m16n16k16.row.col.f32.f32
                  {d0, d1, d2, d3, d4, d5, d6, d7}, ...;
    wmma.store.d.sync.m16n16k16.row.f32
                  [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};
    
    // Store s32 accumulator for m16n16k16 shape:
    .reg .b32 d<8>;
    wmma.store.d.sync.aligned.m16n16k16.row.s32
                  [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};
    
    // Store s32 accumulator for m8n8k128 shape:
    .reg .b32 d<2>
    wmma.store.d.sync.aligned.m8n8k128.row.s32
    [ptr], {d0, d1};
    
    // Store f64 accumulator for m8n8k4 shape:
    .reg .f64 d<2>;
    wmma.store.d.sync.aligned.m8n8k4.row.f64
                  [ptr], {d0, d1};

#####  9.7.14.4.5. [Warp-level Matrix Multiply-and-Accumulate Instruction: `wmma.mma`](<#warp-level-matrix-instructions-wmma-mma>)

`wmma.mma`

Perform a single matrix multiply-and-accumulate operation across a warp

Syntax
    
    
    // Floating point (.f16 multiplicands) wmma.mma
    wmma.mma.sync.aligned.alayout.blayout.shape.dtype.ctype d, a, b, c;
    
    // Integer (.u8/.s8 multiplicands) wmma.mma
    wmma.mma.sync.aligned.alayout.blayout.shape.s32.atype.btype.s32{.satfinite} d, a, b, c;
    
    .alayout = {.row, .col};
    .blayout = {.row, .col};
    .shape  =  {.m16n16k16, .m8n32k16, .m32n8k16};
    .dtype   = {.f16, .f32};
    .atype   = {.s8, .u8};
    .btype   = {.s8, .u8};
    .ctype   = {.f16, .f32};
    

Floating point format `.bf16` `wmma.mma`:
    
    
    wmma.mma.sync.aligned.alayout.blayout.shape.f32.atype.btype.f32 d, a, b, c;
    .alayout = {.row, .col};
    .blayout = {.row, .col};
    .shape   = {.m16n16k16, .m8n32k16, .m32n8k16};
    .atype   = {.bf16 };
    .btype   = {.bf16};
    

Floating point format `.tf32` `wmma.mma`:
    
    
    wmma.mma.sync.aligned.alayout.blayout.shape.f32.atype.btype.f32 d, a, b, c;
    .alayout = {.row, .col};
    .blayout = {.row, .col};
    .shape   = {.m16n16k8 };
    .atype   = {.tf32 };
    .btype   = {.tf32};
    

Floating point Double precision `wmma.mma`:
    
    
    wmma.mma.sync.aligned.alayout.blayout.shape{.rnd}.f64.f64.f64.f64 d, a, b, c;
    .alayout = {.row, .col};
    .blayout = {.row, .col};
    .shape   = {.m8n8k4 };
    .rnd = { .rn, .rz, .rm, .rp };
    

Sub-byte (`.u4`/`.s4` multiplicands) `wmma.mma`:
    
    
    wmma.mma.sync.aligned.row.col.shape.s32.atype.btype.s32{.satfinite} d, a, b, c;
    .shape  = {.m8n8k32};
    .atype  = {.s4, .u4};
    .btype  = {.s4, .u4};
    

Single-bit (`.b1` multiplicands) `wmma.mma`:
    
    
    wmma.mma.op.popc.sync.aligned.row.col.shape.s32.atype.btype.s32 d, a, b, c;
    .shape  = {.m8n8k128};
    .atype  = {.b1};
    .btype  = {.b1};
    .op     = {.xor, .and}
    

Description

Perform a warp-level matrix multiply-and-accumulate computation `D = A * B + C` using matrices A, B and C loaded in registers `a`, `b` and `c` respectively, and store the result matrix in register `d`. The register arguments `a`, `b`, `c` and `d` hold unspecified fragments of the corresponding matrices as described in [Matrix Fragments for WMMA](<#warp-level-matrix-fragment>)

The qualifiers `.dtype`, `.atype`, `.btype` and `.ctype` indicate the data-type of the elements in the matrices D, A, B and C respectively.

For `wmma.mma` without explicit `.atype` and `.btype`: `.atype` and `.btype` are implicitly set to `.f16`.

For integer `wmma`, `.ctype` and `.dtype` must be specified as `.s32`. Also, the values for `.atype` and `.btype` must be the same, i.e., either both are `.s8` or both are `.u8`.

For sub-byte single-bit `wmma`, `.ctype` and `.dtype` must be specified as `.s32`. Also, the values for `.atype` and `.btype` must be the same; i.e., either both are `.s4`, both are `.u4`, or both are `.b1`.

For single-bit `wmma`, multiplication is replaced by a sequence of logical operations; specifically, `wmma.xor.popc` and `wmma.and.popc` computes the XOR, AND respectively of a 128-bit row of A with a 128-bit column of B, then counts the number of set bits in the result (`popc`). This result is added to the corresponding element of C and written into D.

The qualifiers `.alayout` and `.blayout` must match the layout specified on the `wmma.load` instructions that produce the contents of operands `a` and `b` respectively. Similarly, the qualifiers `.atype`, `.btype` and `.ctype` must match the corresponding qualifiers on the `wmma.load` instructions that produce the contents of operands `a`, `b` and `c` respectively.

The `.shape` qualifier must match the `.shape` qualifier used on the `wmma.load` instructions that produce the contents of all three input operands `a`, `b` and `c` respectively.

The destination operand `d` is a brace-enclosed vector expression that matches the `.shape` of the fragment computed by the `wmma.mma` instruction.

Saturation at the output:
    

The optional qualifier `.satfinite` indicates that the final values in the destination register are saturated as follows:

  * The output is clamped to the minimum or maximum 32-bit signed integer value. Otherwise, if the accumulation would overflow, the value wraps.


Precision and rounding for `.f16` floating point operations:
    

Element-wise multiplication of matrix A and B is performed with at least single precision. When `.ctype` or `.dtype` is `.f32`, accumulation of the intermediate values is performed with at least single precision. When both `.ctype` and `.dtype` are specified as `.f16`, the accumulation is performed with at least half precision.

The accumulation order, rounding and handling of subnormal inputs is unspecified.

Precision and rounding for `.bf16`, `.tf32` floating point operations:
    

Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation of the intermediate values is performed with at least single precision.

The accumulation order, rounding and handling of subnormal inputs is unspecified.

Rounding modifiers on double precision `wmma.mma` (default is `.rn`):

`.rn`
    

mantissa LSB rounds to nearest even

`.rz`
    

mantissa LSB rounds towards zero

`.rm`
    

mantissa LSB rounds towards negative infinity

`.rp`
    

mantissa LSB rounds towards positive infinity

The mandatory `.sync` qualifier indicates that `wmma.mma` causes the executing thread to wait until all threads in the warp execute the same `wmma.mma` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same `wmma.mma` instruction. In conditionally executed code, a `wmma.mma` instruction should only be used if it is known that all threads in the warp evaluate the condition identically, otherwise behavior is undefined.

The behavior of `wmma.mma` is undefined if all threads in the same warp do not use the same qualifiers, or if any thread in the warp has exited.

PTX ISA Notes

Introduced in PTX ISA version 6.0.

`.m8n32k16` and `.m32n8k16` introduced in PTX ISA version 6.1.

Integer, sub-byte integer and single-bit `wmma` introduced in PTX ISA version 6.3.

Double precision and alternate floating point precision `wmma` introduced in PTX ISA version 7.0.

Support for `.and` operation in single-bit `wmma` introduced in PTX ISA version 7.1.

Modifier `.aligned` is required from PTX ISA version 6.3 onwards, and considered implicit in PTX ISA versions less than 6.3.

Support for `.satfinite` on floating point `wmma.mma` is deprecated in PTX ISA version 6.4 and is removed from PTX ISA version 6.5.

Target ISA Notes

Floating point `wmma` requires `sm_70` or higher.

Integer `wmma` requires `sm_72` or higher.

Sub-byte and single-bit `wmma` requires `sm_75` or higher.

Double precision, alternate floating point precision `wmma` require `sm_80` or higher.

`.and` operation in single-bit `wmma` requires `sm_80` or higher.

Examples
    
    
    .global .align 32 .f16 A[256], B[256];
    .global .align 32 .f32 C[256], D[256];
    .reg .b32 a<8> b<8> c<8> d<8>;
    
    wmma.load.a.sync.aligned.m16n16k16.global.row.f16
            {a0, a1, a2, a3, a4, a5, a6, a7}, [A];
    wmma.load.b.sync.aligned.m16n16k16.global.col.f16
            {b0, b1, b2, b3, b4, b5, b6, b7}, [B];
    
    wmma.load.c.sync.aligned.m16n16k16.global.row.f32
            {c0, c1, c2, c3, c4, c5, c6, c7}, [C];
    
    wmma.mma.sync.aligned.m16n16k16.row.col.f32.f32
            {d0, d1, d2, d3, d4, d5, d6, d7},
            {a0, a1, a2, a3, a4, a5, a6, a7},
            {b0, b1, b2, b3, b4, b5, b6, b7},
            {c0, c1, c2, c3, c4, c5, c6, c7};
    
    wmma.store.d.sync.aligned.m16n16k16.global.col.f32
            [D], {d0, d1, d2, d3, d4, d5, d6, d7};
    
    // Compute an integer WMMA:
    .reg .b32  a, b<4>;
    .reg .b32 c<8>, d<8>;
    wmma.mma.sync.aligned.m8n32k16.row.col.s32.s8.s8.s32
            {d0, d1, d2, d3, d4, d5, d6, d7},
            {a}, {b0, b1, b2,  b3},
            {c0, c1, c2, c3, c4, c5, c6, c7};
    
    // Compute sub-byte WMMA:
    .reg .b32 a, b, c<2> d<2>
    wmma.mma.sync.aligned.m8n8k32.row.col.s32.s4.s4.s32
            {d0, d1}, {a}, {b}, {c0, c1};
    
    // Compute single-bit type WMMA:
    .reg .b32 a, b, c<2> d<2>
    wmma.mma.xor.popc.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32
            {d0, d1}, {a}, {b}, {c0, c1};
    
    // Compute double precision wmma
    .reg .f64 a, b, c<2>, d<2>;
    wmma.mma.sync.aligned.m8n8k4.row.col.f64.f64.f64.f64
            {d0, d1}, {a}, {b}, {c0, c1};
    
    // Compute alternate floating point precision wmma
    .reg .b32 a<2>, b<2>, c<8>, d<8>;
    wmma.mma.sync.aligned.m16n16k8.row.col.f32.tf32.tf32.f32
            {d0, d1, d2, d3, d4, d5, d6, d7},
            {a0, a1, a2, a3}, {b0, b1, b2, b3},
            {c0, c1, c2, c3, c4, c5, c6, c7};